https://revf.tistory.com/280

LangChainÂ ì— ëŒ€í•´ ë“¤ì–´ë³´ì…¨ë‚˜ìš”?
LangChain ì€ LLM ì—ì„œ êµ¬ë™ë˜ëŠ” APPì„ ê°œë°œí•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
LangChain ì—ì„œ ì œê³µë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ë³´ë‹¤ ì‰½ê²Œ LLM ê¸°ìˆ ë“¤ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Â 
í˜„ì¬ëŠ” javascript ì™€ python ìœ¼ë¡œ êµ¬ë¶„í•´ì„œ ê´€ë¦¬ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì ìš©í•˜ë ¤ëŠ” ì–¸ì–´ì— ë§ì¶° ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.
Â 
LangChainì€ ë‹¨ìˆœíˆ API ì—‘ì„¸ìŠ¤ í•˜ëŠ” ê¸°ëŠ¥ë„ ìˆì§€ë§Œ ê·¸ ì™¸ì—ë„ ë‹¤ì–‘í•œ ì»´í¬ë„ŒíŠ¸ë“¤ì´ ì¤€ë¹„ë˜ì–´ ìˆìœ¼ë©°,Â ì•„ë˜ì™€ ê°™ì´ í¬ê²Œ ë‘ ê°€ì§€ ì›ì¹™ì— ê¸°ë°˜í•˜ì—¬ ì‘ì„±ë˜ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.
Â 
Â 
- Be data-aware : ì–¸ì–´ ëª¨ë¸ì„ ë‹¤ë¥¸ ë°ì´í„° ì›ë³¸ì— ì—°ê²°í•©ë‹ˆë‹¤.- Be agentic : ì–¸ì–´ ëª¨ë¸ì´ í•´ë‹¹ í™˜ê²½ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆë„ë¡ í—ˆìš©í•©ë‹ˆë‹¤.
Â 
Â 
LangChain ì‚¬ì´íŠ¸ì—ì„œëŠ” 7ê°œ ì¹´í…Œê³ ë¦¬ì˜ ì»´í¬ë„ŒíŠ¸ë“¤ê³¼ ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€ë“¤ì„ ì†Œê°œí•˜ê³  ìˆìŠµë‹ˆë‹¤.
Â 
Â 
ëª©ì°¨
1. Schema
Â  1.1 ì±„íŒ… ë©”ì„¸ì§€
Â  1.1 ë¬¸ì„œ
2. Models
Â  2.1 ì–¸ì–´ ëª¨ë¸ (LLMs)Â  2.2 ì±„íŒ… ëª¨ë¸
Â  2.3 í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸
3. Prompt
Â  3.1 Prompt
Â  3.2 Prompt Template
Â  3.3 ì˜ˆì œ ì„ íƒê¸° (Example Selector)
Â  3.4 ì¶œë ¥ íŒŒì„œ (Output Parser)
4. Index
Â  4.1 ë¬¸ì„œ ë¡œë” (Document Loader)
Â  4.2 í…ìŠ¤íŠ¸ ë¶„í• ê¸° (Text Splitters)
Â  4.3 ë°±í„° ìŠ¤í† ì–´ (Vector Stores)
Â  4.4 ê²€ìƒ‰ê¸° (Retrievers)
5. Memory
Â  5.1 ì±„íŒ… ë©”ì„¸ì§€ History
6. Chain
Â  6.1 ê°„ë‹¨í•œ Sequential Chain
Â  6.2 ìš”ì•½ Chain
7. Agents
Â  7.1 Tools
Â 
Â 
Â 
1ë¶€. ì»´í¬ë„ŒíŠ¸
LangChain ì—ì„œëŠ” LLM ì‘ì—…ì— í•„ìš”í•œ ê¸°ëŠ¥ì„ ì¶”ìƒí™”ëœ ì»´í¬ë„ŒíŠ¸ë¡œ ì œê³µí•©ë‹ˆë‹¤.
Schema, Model, Prompt, Index, Memory, Chain, Agent ì´ë ‡ê²Œ 7ê°€ì§€ë¡œ ë¶„ë¥˜ëœ ì»´í¬ë„ŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
Â 


Â 
ì´ ê¸€ì—ì„œëŠ” ì£¼ìš” ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì˜ˆì œì™€ í•¨ê»˜ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ì˜ˆì œëŠ” python ì„ ê¸°ì¤€ìœ¼ë¡œ í•©ë‹ˆë‹¤.
Â 
(ì¤€ë¹„) í™˜ê²½ì„¤ì •
1. openai, langchain SDK ì„¤ì¹˜
$ pip install openai
$ pip install langchain
Â 
2. OpenAI API key
2-1) ChatOpenAI ìƒì„± ì‹œ
chat = ChatOpenAI(openai_api_key=openai_api_key)
Â 
2-2) í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export OPENAI_API_KEY="SK-..."
Â 
2-3) jupyter notebook ì‚¬ìš© ì‹œ, í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
import os
os.environ["OPENAI_API_KEY"] = "..."
Â 
Â 
1. Schema
1.1 ì±„íŒ… ë©”ì„¸ì§€
LLMê³¼ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
í˜„ì¬ëŠ” System, Human, AI 3ì¢…ë¥˜ì˜ ì‚¬ìš©ìë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
Â 
- System : AIì—ê²Œ í•´ì•¼ í•  ì¼ì„ ì•Œë ¤ì£¼ëŠ” ë°°ê²½ ì»¨í…ìŠ¤íŠ¸- Human : ì‚¬ìš©ì ë©”ì„¸ì§€- AI : AIê°€ ì‘ë‹µí•œ ë‚´ìš©ì„ ë³´ì—¬ì£¼ëŠ” ìƒì„¸ ë©”ì„¸ì§€
Â 
ì˜ˆì œ1
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage, AIMessage

chat = ChatOpenAI(temperature=.7)
chat(
  [  
    SystemMessage(content="ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ë¬´ì—‡ì„ ë¨¹ì„ì§€ ì•Œì•„ë‚¼ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë©‹ì§„ AI ë´‡ì…ë‹ˆë‹¤."),
    HumanMessage(content="í† ë§ˆí†  ì¢‹ì•„í•˜ëŠ”ë°, ë­˜ ë¨¹ì–´ì•¼ í•˜ë‚˜ìš”??")
  ]
)
AIMessage(content='ì‹ ì„ í•œ ë°”ì§ˆê³¼ ëª¨ì§œë ë¼ ì¹˜ì¦ˆë¥¼ ê³ë“¤ì¸ í† ë§ˆí†  ìƒëŸ¬ë“œë¥¼ ë§Œë“¤ì–´ ë³´ì„¸ìš”.', additional_kwargs={})
Â 
ì˜ˆì œ2) AI ì˜ ì‘ë‹µì„ ì¶”ê°€í•œ ì±„íŒ… ê¸°ë¡ì„ ì „ë‹¬í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
chat(
  [ 
    SystemMessage(content="ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ì–´ë””ë¡œ ì—¬í–‰í• ì§€ ì•Œì•„ë‚¼ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë©‹ì§„ AI ë´‡ì…ë‹ˆë‹¤."),
    HumanMessage(content="í•´ë³€ì´ ì¢‹ì€ë° ì–´ë””ë¡œ ê°€ë©´ ì¢‹ì„ê¹Œìš”?"), 
    AIMessage(content="í”„ë‘ìŠ¤ ë‹ˆìŠ¤ì— ê°€ì•¼ í•´ìš”"), 
    HumanMessage(content="ê·¸ê³³ì— ê°€ë©´ ë˜ ë­˜ í•˜ë©´ ì¢‹ì„ê¹Œìš”?")
  ]
)

AIMessage(content='ë‹ˆìŠ¤ì— ë¨¸ë¬´ëŠ” ë™ì•ˆ ë§¤ë ¥ì ì¸ êµ¬ì‹œê°€ì§€ë¥¼ ë‘˜ëŸ¬ë³´ê³ , ìœ ëª…í•œ í”„ë¡¬ë‚˜
ë“œ ë° ì•µê¸€ë ˆë¥¼ ë°©ë¬¸í•˜ê³ , ë§›ìˆëŠ” í”„ë‘ìŠ¤ ìš”ë¦¬ë¥¼ ë§›ë³¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.', 
additional_kwargs={})
Â 
ì˜ˆì œ3) ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë° í•˜ëŠ” ë°©ë²• (jupyter notebook)
from langchain.callbacks.base import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

chat = ChatOpenAI(streaming=True, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=True, temperature=0)
resp = chat([HumanMessage(content="Write me a song about sparkling water.")])
Â 
Â 
1.2 ë¬¸ì„œ
í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ë‹´ê³ ìˆëŠ” ê°ì²´ì…ë‹ˆë‹¤.
from langchain.schema import Document

Document(page_content="ì´ê²ƒì€ ë‚´ ë¬¸ì„œì…ë‹ˆë‹¤. ë‹¤ë¥¸ ê³³ì—ì„œ ìˆ˜ì§‘í•œ í…ìŠ¤íŠ¸ë¡œ ê°€ë“ ì°¨ ìˆìŠµë‹ˆë‹¤.",
metadata={
    'my_document_id' : 234234,
    'my_document_source' : "The LangChain Papers",
    'my_document_create_time' : 1680013019
})

Document(
  page_content="ì´ ë¬¸ì„œëŠ” ì œ ë¬¸ì„œì…ë‹ˆë‹¤. ë‹¤ë¥¸ ê³³ì—ì„œ ìˆ˜ì§‘í•œ í…ìŠ¤íŠ¸ë¡œ ê°€ë“í•©ë‹ˆë‹¤.", 
  lookup_str='',
  metadata={
    'my_document_id': 234234, 
    'my_document_source': 'The LangChain Papers', 
    'my_document_create_time': 1680013019
  }, 
  lookup_index=0
)
Â 
ì˜ˆì œ1) PyPDFLoader - PDF to Document
from langchain.document_loaders import PyPDFLoader

loader = PyPDFLoader("example_data/layout-parser-paper.pdf")
pages = loader.load_and_split()
Â 
Â 
2. Models
2.1 ì–¸ì–´ ëª¨ë¸ (LLMs)
í…ìŠ¤íŠ¸ ë¬¸ìì—´ì„ ì…ë ¥í•˜ê³ , í…ìŠ¤íŠ¸ ë¬¸ìì—´ì„ ì¶œë ¥í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.
LangChain ì€ LLM ê³µê¸‰ìê°€ ì•„ë‹ˆë©°, ì¸í„°í˜ì´ìŠ¤ë§Œ ì œê³µí•©ë‹ˆë‹¤.
Â 
ì˜ˆì œ1) OpenAI
from langchain.llms import OpenAI
from langchain import PromptTemplate, LLMChain

template = """Question: {question}
Answer: Let's think step by step."""

prompt = PromptTemplate(template=template, input_variables=["question"])

llm = OpenAI()

llm_chain = LLMChain(prompt=prompt, llm=llm)

question = "ì €ìŠ¤í‹´ ë¹„ë²„ê°€ íƒœì–´ë‚œ í•´ì— ìŠˆí¼ë³¼ì—ì„œ ìš°ìŠ¹í•œ NFL íŒ€?"

llm_chain.run(question)

'ì €ìŠ¤í‹´ ë¹„ë²„ëŠ” 1994ë…„ì— íƒœì–´ë‚¬ìœ¼ë¯€ë¡œ ê·¸ í•´ì— ìŠˆí¼ë³¼ì—ì„œ ìš°ìŠ¹í•œ NFL íŒ€ì€ ëŒˆëŸ¬ìŠ¤ ì¹´ìš°ë³´ì´ì¦ˆì…ë‹ˆë‹¤.'
Â 
Â 
Â 
2.2 ì±„íŒ… ëª¨ë¸
ì±„íŒ… ëª¨ë¸ì€ ì–¸ì–´ ëª¨ë¸ì˜ ë³€í˜•ìœ¼ë¡œ, ë‚´ë¶€ì ìœ¼ë¡œëŠ” ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì§€ë§Œ ë…¸ì¶œë˜ëŠ” ì¸í„°í˜ì´ìŠ¤ëŠ” ì•½ê°„ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ ë³´ë‹¤ ë‚˜ì€ ì¶”ìƒí™”ë¥¼ ìœ„í•´ì„œ ì§€ì†ì ìœ¼ë¡œ ê°œì„ ì´ ì´ë¤„ì§€ê³  ìˆìŠµë‹ˆë‹¤.
Â 
ì˜ˆì œ1) Simple Chat
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage, AIMessage

chat = ChatOpenAI()
chat(
  [
    SystemMessage(content="ì‚¬ìš©ìê°€ ë¬´ìŠ¨ ë§ì„ í•˜ë“  ë†ë‹´ë§Œ í•˜ëŠ” ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ” AI ë´‡ì…ë‹ˆë‹¤."),
    HumanMessage(content="ë‰´ìš•ì— ê°€ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?")
  ]
)

AIMessage(content="ê±¸ì„ ìˆ˜ë„ ìˆì§€ë§Œ ì‹œê°„ì´ ë§ì§€ ì•Šë‹¤ë©´ ì¶”ì²œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. íŒ”ì„ ì„¸ê²Œ í„ëŸ­ì´ë©° ë‚ ì•„ê°ˆ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?", additional_kwargs={})
Â 
Â 
ì˜ˆì œ2) í…œí”Œë¦¿ ì´ìš©
template="ë‹¹ì‹ ì€ {input_language}ë¥¼ {output_language}ë¡œ ë²ˆì—­í•˜ëŠ” ìœ ìš©í•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤."
system_message_prompt = SystemMessagePromptTemplate.from_template(template)
human_template="{text}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])

# í˜•ì‹ì´ ì§€ì •ëœ ë©”ì‹œì§€ì—ì„œ ì±„íŒ… ì™„ë£Œ ê°€ì ¸ì˜¤ê¸°
chat(
  chat_prompt.format_prompt(
    input_language="English", 
    output_language="French", 
    text="I love programming."
  ).to_messages()
)

AIMessage(content="J'adore la programmation.", additional_kwargs={})
Â 
Â 
Â 
2.3 í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸
í…ìŠ¤íŠ¸ë¥¼ ë²¡í„° (í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ ë¥¼ ë‹´ê³  ìˆëŠ” ì¼ë ¨ì˜ ìˆ«ì) ë¡œ ë³€ê²½í•©ë‹ˆë‹¤. ì£¼ë¡œ ë‘ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë¹„êµí•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
Â 
ì˜ˆì œ)
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
text = "ì•ˆë…•í•˜ì„¸ìš”! í•´ë³€ì— ê°ˆ ì‹œê°„ì…ë‹ˆë‹¤"
text_embedding = embeddings.embed_query(text)

print (f"ì„ë² ë”© ê¸¸ì´ : {len(text_embedding)}")
print (f"ìƒ˜í”Œì€ ë‹¤ì›€ê³¼ ê°™ìŠµë‹ˆë‹¤ : {text_embedding[:5]}...")

ì„ë² ë”© ê¸¸ì´ : 1536
ìƒ˜í”Œì€ ë‹¤ì›€ê³¼ ê°™ìŠµë‹ˆë‹¤: [-0.00020583387231454253, -0.003205398330464959, -
0.0008301587076857686, -0.01946892775595188, -0.015162716619670391]...
Â 
ì˜ˆì œ2) ì•„ë˜ì™€ ê°™ì´ ë‹¤ë¥¸ ëª¨ë¸ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
from langchain.embeddings.openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(model_name="ada")
text = "This is a test document."
query_result = embeddings.embed_query(text)
doc_result = embeddings.embed_documents([text])
Â 
Â 
Â 
3. Prompt
ëª¨ë¸ì„ í”„ë¡œê·¸ë˜ë° í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì€ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë°ì´í„° ìœ í˜• (ì´ë¯¸ì§€, ì˜¤ë””ì˜¤) ë“±ì„ ê³ ë ¤í•˜ì—¬ ì¶”ìƒí™” ì‘ì—…ì´ ì§„í–‰ë˜ê³  ìˆìœ¼ë©°, í˜„ì¬ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
Â 
3.1 Prompt
Â 
prompt = """
Today is Monday, tomorrow is Wednesday.
What is wrong with that statement?
"""

llm(prompt)
'\nThe statement is incorrect; tomorrow is Tuesday, not Wednesday.'
Â 
Â 
3.2 Prompt Template
ì‚¬ìš©ìë¡œë¶€í„° ì¼ë ¨ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì ¸ì™€ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ ë¬¸ìì—´ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
Â 
ì˜ˆì œ)
from langchain import PromptTemplate

template = """
ì‹ ìƒ íšŒì‚¬ì˜ ë„¤ì´ë° ì»¨ì„¤í„´íŠ¸ ì—­í• ì„ í•´ ì£¼ì…¨ìœ¼ë©´ í•©ë‹ˆë‹¤.
ë‹¤ìŒì€ ì¢‹ì€ íšŒì‚¬ ì´ë¦„ì˜ ëª‡ ê°€ì§€ ì˜ˆì…ë‹ˆë‹¤:
- ê²€ìƒ‰ ì—”ì§„, Google 
- ì†Œì…œ ë¯¸ë””ì–´, Facebook 
- ë™ì˜ìƒ ê³µìœ , YouTube

ì´ë¦„ì€ ì§§ê³  ëˆˆì— ì˜ ë„ë©° ê¸°ì–µí•˜ê¸° ì‰¬ì›Œì•¼ í•©ë‹ˆë‹¤.
{product}ì„ ë§Œë“œëŠ” íšŒì‚¬ì˜ ì¢‹ì€ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?
"""

prompt = PromptTemplate(
    input_variables=["product"],
    template=template,
)
Â 
Â 
ì˜ˆì œ2) PromptTemplate í´ë˜ìŠ¤ ì´ìš©
from langchain import PromptTemplate

# ì…ë ¥ ë³€ìˆ˜ê°€ ì—†ëŠ” í”„ë¡¬í”„íŠ¸ ì˜ˆì œ
no_input_prompt = PromptTemplate(input_variables=[], template="Tell me a joke.")
no_input_prompt.format()
# -> "Tell me a joke."

# í•˜ë‚˜ì˜ ì…ë ¥ ë³€ìˆ˜ê°€ ìˆëŠ” ì˜ˆì œ í”„ë¡¬í”„íŠ¸
one_input_prompt = PromptTemplate(input_variables=["adjective"], template="Tell me a {adjective} joke.")
one_input_prompt.format(adjective="funny")
# -> "Tell me a funny joke."

# ì—¬ëŸ¬ ì…ë ¥ ë³€ìˆ˜ê°€ ìˆëŠ” í”„ë¡¬í”„íŠ¸ ì˜ˆì œ
multiple_input_prompt = PromptTemplate(
    input_variables=["adjective", "content"], 
    template="Tell me a {adjective} joke about {content}."
)
multiple_input_prompt.format(adjective="funny", content="chickens")
# -> "Tell me a funny joke about chickens."
Â 
Â 
3.3 ì˜ˆì œ ì„ íƒê¸° (Example Selector)
í”„ë¡¬í”„íŠ¸ì—ì„œ ìƒí™©ì— ë§ëŠ” ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ ë°°ì¹˜í•  ìˆ˜ ìˆëŠ” ì˜ˆì œ ì¤‘ì—ì„œ ì‰½ê²Œ ì„ íƒí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.
Â 
ì˜ˆì œ)
from langchain.prompts.example_selector import
SemanticSimilarityExampleSelector
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.prompts import FewShotPromptTemplate, PromptTemplate
from langchain.llms import OpenAI

llm = OpenAI(model_name="text-davinci-003")
example_prompt = PromptTemplate(
  input_variables=["input", "output"],
  template="Example Input: {input}\nExample Output: {output}",
)

# ëª…ì‚¬ê°€ ë°œê²¬ë˜ëŠ” ìœ„ì¹˜ì˜ ì˜ˆ
examples = [
  {"input": "pirate", "output": "ship"},
  {"input": "pilot", "output": "plane"},
  {"input": "driver", "output": "car"},
  {"input": "tree", "output": "ground"},
  {"input": "bird", "output": "nest"},
]

# SemanticSimilarityExampleSelectorëŠ” ì˜ë¯¸ë¡ ì  ì˜ë¯¸ì— ë”°ë¼ ì…ë ¥ê³¼ ìœ ì‚¬í•œ ì˜ˆì œë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
example_selector = SemanticSimilarityExampleSelector.from_examples(
  examples,
  OpenAIEmbeddings(openai_api_key=openai_api_key),  # ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì„ë² ë”© í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
  FAISS,  # ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” VectorStore í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
  k=2 # ìƒì„±í•  ì˜ˆì œ ê°œìˆ˜ì…ë‹ˆë‹¤.
)

similar_prompt = FewShotPromptTemplate(
  example_selector=example_selector,  # ì˜ˆì œ ì„ íƒì— ë„ì›€ì´ ë˜ëŠ” ê°œì²´
  example_prompt=example_prompt,  # í”„ë¡¬í”„íŠ¸
  prefix="Give the location an item is usually found in",  # í”„ë¡¬í”„íŠ¸ì˜ ìƒë‹¨ê³¼ í•˜ë‹¨ì— ì¶”ê°€ë˜ëŠ” ì‚¬ìš©ì ì§€ì • ì‚¬í•­
  suffix="Input: {noun}\nOutput:",
  input_variables=["noun"],  # í”„ë¡¬í”„íŠ¸ê°€ ìˆ˜ì‹ í•  ì…ë ¥ í•­ëª©
)

# ëª…ì‚¬ë¥¼ ì„ íƒ
my_noun = "student"

print(similar_prompt.format(noun=my_noun))

í•­ëª©ì´ ì¼ë°˜ì ìœ¼ë¡œ ë°œê²¬ë˜ëŠ” ìœ„ì¹˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
Example Input: driver
Example Output: car

Example Input: pilot
Example Output: plane

Input: student
Output:

llm(similar_prompt.format(noun=my_noun))
' classroom'

Â 
Â 
Â 
3.4 ì¶œë ¥ íŒŒì„œ (Output Parser)
ì¼ë°˜ì ìœ¼ë¡œ LLMì€ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë³´ë‹¤ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì–»ê³  ì‹¶ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ëŸ° ê²½ìš° ì¶œë ¥ íŒŒì„œë¥¼ ì´ìš©í•˜ì—¬ LLM ì‘ë‹µì„ êµ¬ì¡°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì¶œë ¥ íŒŒì„œëŠ” ë‘ ê°€ì§€ ì»¨ì…‰ì„ ê°–ê³  ìˆìŠµë‹ˆë‹¤.
Â 
- Format instructions : ì›í•˜ëŠ” ê²°ê³¼ì˜ í¬ë©§ì„ ì§€ì •í•˜ì—¬ LLMì— ì•Œë ¤ì¤ë‹ˆë‹¤.- Parser : ì›í•˜ëŠ” í…ìŠ¤íŠ¸ ì¶œë ¥ êµ¬ì¡° (ë³´í†µ json) ì„ ì¶”ì¶œí•˜ë„ë¡ í•©ë‹ˆë‹¤.
Â 
ì˜ˆì œ1) CommaSeparatedListOutputParser
from langchain.output_parsers import CommaSeparatedListOutputParser
from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI

output_parser = CommaSeparatedListOutputParser()

format_instructions = output_parser.get_format_instructions()
prompt = PromptTemplate(
    template="List five {subject}.\n{format_instructions}",
    input_variables=["subject"],
    partial_variables={"format_instructions": format_instructions}
)

model = OpenAI(temperature=0)

_input = prompt.format(subject="ice cream flavors")
output = model(_input)

output_parser.parse(output)

['Vanilla',
 'Chocolate',
 'Strawberry',
 'Mint Chocolate Chip',
 'Cookies and Cream']
Â 
Â 
ì˜ˆì œ2) ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸ êµì •
from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.llms import OpenAI

llm = OpenAI(model_name="text-davinci-003")

# ì‘ë‹µì„ ì–´ë–»ê²Œ êµ¬ì„±í•˜ê³  ì‹¶ì€ì§€ ì…ë ¥í•©ë‹ˆë‹¤. ì´ê²ƒì€ ê¸°ë³¸ì ìœ¼ë¡œ ë©‹ì§„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì…ë‹ˆë‹¤.
response_schemas = [
  ResponseSchema(name="bad_string", description="This a poorly formatted user input string"),
  ResponseSchema(name="good_string", description="This is your response, a reformatted response")
]

# ì¶œë ¥ êµ¬ë¬¸ ë¶„ì„ ë°©ë²•
output_parser = StructuredOutputParser.from_response_schemas(response_schemas)

# ì„œì‹ì„ ì§€ì •í•˜ë ¤ë©´ ìƒì„±í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì°¸ì¡°í•˜ì„¸ìš”.
format_instructions = output_parser.get_format_instructions()
print (format_instructions)

ì¶œë ¥ì€ ë‹¤ìŒ ìŠ¤í‚¤ë§ˆ í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ìŠ¤ë‹ˆí«ì´ì–´ì•¼ í•©ë‹ˆë‹¤.:
'''json
{
"bad_string": string // This a poorly formatted user input
string
"good_string": string // This is your response, a reformatted
response
}
'''
template = """
You will be given a poorly formatted string from a user.
Reformat it and make sure all the words are spelled correctly
{format_instructions}
% USER INPUT:
{user_input}
YOUR RESPONSE:
"""
prompt = PromptTemplate(
  input_variables=["user_input"], partial_variables={"format_instructions": format_instructions},
  template=template
)

promptValue = prompt.format(user_input="welcom to califonya!")
print(promptValue)

ì‚¬ìš©ìë¡œë¶€í„° ì˜ëª»ëœ í˜•ì‹ì˜ ë¬¸ìì—´ì„ ë°›ê²Œ ë©ë‹ˆë‹¤..
í˜•ì‹ì„ ë‹¤ì‹œ ì§€ì •í•˜ê³  ëª¨ë“  ë‹¨ì–´ì˜ ì² ìê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•©ë‹ˆë‹¤. ì¶œë ¥ì€ ë‹¤ìŒ ìŠ¤í‚¤ë§ˆ í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ìŠ¤ë‹ˆí«ì´ì–´ì•¼ í•©ë‹ˆë‹¤.:

{
"bad_string": string // This a poorly formatted user input
string
"good_string": string // This is your response, a reformatted
response
}

% USER INPUT:
welcom to califonya!
YOUR RESPONSE:
llm_output = llm(promptValue)
llm_output
'`json\n{\n\t"bad_string": "welcom to califonya!",\n\t"good_string":
"Welcome to California!"\n}\n`' 

output_parser.parse(llm_output)
{
'bad_string': 'welcom to califonya!', 
'good_string': 'Welcome to California!'
}
Â 
Â 
Â 
4. Index
IndexëŠ” LLM ì´ ë‹¤ë¥¸ ì†ŒìŠ¤ì—ì„œ ë¬¸ì„œë¥¼ ì‰½ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ë¬¸ì„œ ì‘ì—…ì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜, ë‹¤ì–‘í•œ ìœ í˜•ì˜ Index, ê·¸ë¦¬ê³  ì´ëŸ¬í•œ Index ë¥¼ ì²´ì´ë‹í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
Â 
ì´ì œ ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ê°€ì ¸ì˜¤ëŠ” ê²ƒì„ LangChainì„ ì´ìš©í•˜ì—¬ ì•„ì£¼ ê°„ë‹¨íˆ í•´ê²°í•´ë³´ì„¸ìš”.
Â 
4.1 ë¬¸ì„œ ë¡œë” (Document Loader)
CSV, HTML, ë©”ì¼, Image, PDF, PPT, Site, Youtube ë“± ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ Document ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆëŠ” Loader ê°€ ì œê³µë˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ì²´ ëª©ë¡ì€ ì•„ë˜ ë§í¬ì—ì„œ ì°¸ê³ í•´ì£¼ì„¸ìš”.
Â 
Document Loader ì „ì²´ ëª©ë¡
Â 
ì˜ˆì œ1) ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°
from langchain.document_loaders import HNLoader

loader = HNLoader("https://news.ycombinator.com/item?id=34422627")
data = loader.load()

print (f"Found {len(data)} comments")
print (f"Here's a sample:\n\n{''.join([x.page_content[:150] for x in data[:2]])}")
Â 
Â 
ì˜ˆì œ2) ì‚¬ì´íŠ¸ ë¡œë”
from langchain.document_loaders import UnstructuredURLLoader

urls = [
    "https://www.understandingwar.org/backgrounder/russian-offensive-campaign-assessment-february-8-2023",
    "https://www.understandingwar.org/backgrounder/russian-offensive-campaign-assessment-february-9-2023"
]
loader = UnstructuredURLLoader(urls=urls)
data = loader.load()
Â 
Â 
ì˜ˆì œ3) ìœ íŠœë¸Œ ìë§‰ ë¶ˆëŸ¬ì˜¤ê¸°
from langchain.document_loaders import YoutubeLoader

!pip install youtube-transcript-api
loader = YoutubeLoader.from_youtube_url("ìœ íŠœë¸ŒURL", add_video_info=True)
loader.load()
Â 
Â 
4.2 í…ìŠ¤íŠ¸ ë¶„í• ê¸° (Text Splitters)
ì±…ê³¼ ê°™ì´ ë¬¸ì„œê°€ ë„ˆë¬´ ê¸¸ì–´ì„œ LLM ì— í•œë²ˆì— ì…ë ¥ì´ ì–´ë ¤ìš´ ê²½ìš°, ë¬¸ì„œë¥¼ ì˜ê²Œ ìª¼ê°œì•¼ í•©ë‹ˆë‹¤. ì´ ê²½ìš° í…ìŠ¤íŠ¸ ë¶„í• ê¸°ë¥¼ ì´ìš©í•˜ì—¬ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Â 
ì˜ˆì œ1) OpenAIì˜ ì˜¤í”ˆì†ŒìŠ¤ì¸ tiktoken ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ëœ í† í°ì„ ì¶”ì •í•œ ë¶„í• 
with open('../../../state_of_the_union.txt') as f:
    state_of_the_union = f.read()

from langchain.text_splitter import CharacterTextSplitter

text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=100, chunk_overlap=0)
texts = text_splitter.split_text(state_of_the_union)

print(texts[0])
Â 
Â 
ì˜ˆì œ2) ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ë¶„í• ê¸°
from langchain.text_splitter import MarkdownTextSplitter

markdown_text = """
ğŸ¦œï¸ğŸ”— LangChain

âš¡ Building applications with LLMs through composability âš¡

Quick Install

Hopefully this code block isn't split
pip install langchain

As an open source project in a rapidly developing field, we are extremely open to contributions.
"""
markdown_splitter = MarkdownTextSplitter(chunk_size=100, chunk_overlap=0)

docs = markdown_splitter.create_documents([markdown_text])
Â 
Â 
4.3 ë²¡í„° ìŠ¤í† ì–´ (Vector Stores)
ë²¡í„° (Vector)ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì™€ ê´€ë ¨ëœ ê¸°ëŠ¥ì…ë‹ˆë‹¤. ë²¡í„° ì €ì¥ì†Œ ì‘ì—…ì˜ í•µì‹¬ ë¶€ë¶„ì€ ì¼ë°˜ì ìœ¼ë¡œ ì„ë² ë”©ì„ í†µí•´ ìƒì„±ë˜ëŠ” ë²¡í„°ë¥¼ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.
Â 
ì˜ˆì œ) Vector ì €ì¥
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

loader = TextLoader('data/PaulGrahamEssays/worked.txt')
documents = loader.load()

# ìŠ¤í”Œë¦¬í„° ì¤€ë¹„í•˜ê¸°
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)

# ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë¶„í• 
texts = text_splitter.split_documents(documents)

# ì„ë² ë”© ì—”ì§„ ì¤€ë¹„í•˜ê¸°
embeddings = OpenAIEmbeddings()

print (f"You have {len(texts)} documents")
You have 78 documents

embedding_list = embeddings.embed_documents([text.page_content for text in texts])

print (f"You have {len(embedding_list)} embeddings")
print (f"Here's a sample of one: {embedding_list[0][:3]}...")
Â 
Â 
4.4 ê²€ìƒ‰ê¸° (Retrievers)
ë¦¬íŠ¸ë¦¬ë²„ ì¸í„°í˜ì´ìŠ¤ëŠ” ë¬¸ì„œë¥¼ ì‰½ê²Œ ê²°í•©í•  ìˆ˜ ìˆëŠ” ì¼ë°˜ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
í˜„ì¬ ChatGPT Plugin Retriever ì™€ VectorStore Retriever ê°€ ìˆìŠµë‹ˆë‹¤.
Â 
ì˜ˆì œ) VectorStore Retriever
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

loader = TextLoader('data/PaulGrahamEssays/worked.txt')
documents = loader.load()

#ìŠ¤í”Œë¦¬í„° ì¤€ë¹„í•˜ê¸°
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=50)

# ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë¶„í• 
texts = text_splitter.split_documents(documents)

# ì„ë² ë”© ì—”ì§„ ì¤€ë¹„í•˜ê¸°
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)

# í…ìŠ¤íŠ¸ ì‚½ì…
db = FAISS.from_documents(texts, embeddings)

# ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ì´ˆê¸°í™”í•˜ì„¸ìš”. ë¬¸ì„œ 1ê±´ë§Œ ë°˜í™˜ ìš”ì²­í•˜ê¸°
retriever = db.as_retriever()

retriever

VectorStoreRetriever(vectorstore=<langchain.vectorstores.faiss.FAISS
object at 0x7fb81007a9d0>, search_type='similarity', search_kwargs={})
docs = retriever.get_relevant_documents("what types of things did the
author want to build?")

print("\n\n".join([x.page_content[:200] for x in docs[:2]]))
Â 
Â 
Â 
5. Memory
ê¸°ë³¸ì ìœ¼ë¡œ ì²´ì¸ê³¼ ì—ì´ì „íŠ¸ëŠ” ìƒíƒœë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¦‰, ì¿¼ë¦¬ê°€ ìˆ˜í–‰ë˜ë©´ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
Memory ì»´í¬ë„ŒíŠ¸ëŠ” LLM ì´ ì •ë³´ë¥¼ ê¸°ì–µí•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. ê°„ë‹¨í•˜ê²ŒëŠ” ê³¼ê±° ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ì–µí•  ìˆ˜ ë„ ìˆê³ , ë” ë³µì¡í•œ ì •ë³´ë¥¼ ê²€ìƒ‰ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
Â 
Memory ì»´í¬ë„ŒíŠ¸ ëª©ë¡
Â 
5.1 ì±„íŒ… ë©”ì„¸ì§€ History
ChatMessageHisotry í´ë˜ìŠ¤ëŠ” Human, AI ë©”ì„¸ì§€ë¥¼ ì €ì¥í•œ ë‹¤ìŒ ëª¨ë‘ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Â 
ì˜ˆì œ)
from langchain.memory import ChatMessageHistory
from langchain.chat_models import ChatOpenAI

chat = ChatOpenAI()

history = ChatMessageHistory()

history.add_ai_message("hi!")
history.add_user_message("what is the capital of france?")

history.messages
Â 
Â 
Â 
6. Chain
ë‹¤ì–‘í•œ LLM í˜¸ì¶œí•˜ëŠ”ë° ì‚¬ìš©ë˜ëŠ” ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.
Â 
6.1 ê°„ë‹¨í•œ Sequential Chains
LLMChain ì„ ì´ìš©í•˜ì—¬ LLM ì¶œë ¥ì„ ë‹¤ë¥¸ LMMì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
Â 
ì˜ˆì œ) SimpleSequentialChain
from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.chains import SimpleSequentialChain

llm = OpenAI(temperature=1)
template = """
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì‚¬ìš©ìê°€ ì œì•ˆí•˜ëŠ” ì§€ì—­ì˜ í´ë˜ì‹ ìš”ë¦¬ë¥¼ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.
% USER LOCATION
{user_location}
YOUR RESPONSE:
"""

prompt_template = PromptTemplate(input_variables=["user_location"], template=template)

# ë‚´ 'ìœ„ì¹˜' ì²´ì¸ì„ ë³´ê´€í•©ë‹ˆë‹¤.
location_chain = LLMChain(llm=llm, prompt=prompt_template)
template = """
ì‹ì‚¬ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ì§‘ì—ì„œ í•´ë‹¹ ìš”ë¦¬ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì— ëŒ€í•œ ì§§ê³  ê°„ë‹¨í•œ ë ˆì‹œí”¼ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
% MEAL
{user_meal}
YOUR RESPONSE:
"""

prompt_template = PromptTemplate(input_variables=["user_meal"], template=template)

# ë‚´ 'ì‹ì‚¬' ì²´ì¸ ë³´ê´€
meal_chain = LLMChain(llm=llm, prompt=prompt_template)

overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)

review = overall_chain.run("ë¡œë§ˆ")
Â 
Â 
6.2. ìš”ì•½ ì²´ì¸
í•œë²ˆì— ì²˜ë¦¬ê°€ ì–´ë ¤ìš´ ë¬¸ì„œë¥¼ ë‚˜ëˆ ì„œ ìš”ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Â 
ì˜ˆì œ) map\_reduce Chain
from langchain.chains.summarize import load_summarize_chain
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

loader = TextLoader('data/PaulGrahamEssays/disc.txt')
documents = loader.load()

# ìŠ¤í”Œë¦¬í„° ì¤€ë¹„í•˜ê¸°
text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=50)

# ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë¶„í• 
texts = text_splitter.split_documents(documents)

map-reduce ë¥¼ í†µí•´ ê¸´ ì „ì²´ ë¬¸ì„œë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
chain = load_summarize_chain(llm, chain_type="map_reduce", verbose=True)
chain.run(texts)
Â 
Â 
Â 
7. Agents
ì‚¬ìš©ì ì…ë ¥ì— ë”°ë¼ AgentëŠ” ì—¬ëŸ¬ ë„êµ¬ ì¤‘ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ê²½ìš° ë„êµ¬ë¥¼ ê²°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
AgnetëŠ” LLM ì„ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰í•¼ ì‘ì—…ê³¼ ìˆœì„œë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶œë ¥ì„ ê´€ì°°í•˜ê±°ë‚˜ ì‚¬ìš©ìì—ê²Œ ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Â 
7.1 Tools
êµ¬ê¸€ ê²€ìƒ‰, ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ, Python REPL ë“±ì„ ì´ìš©í•˜ì—¬ í˜„ì¬ ë¬¸ìì—´ì„ ì…ë ¥ë°›ì•„ ê²°ê³¼ê°’ì„ ì¶œë ¥í•©ë‹ˆë‹¤. OpenAI Plugins ê³¼ ìœ ì‚¬í•œ ì˜ì—­ì…ë‹ˆë‹¤.
Â 
ì˜ˆì œ) êµ¬ê¸€ ê²€ìƒ‰
# êµ¬ê¸€ API í™˜ê²½ì„¤ì •
import os
os.environ["GOOGLE_CSE_ID"] = ""
os.environ["GOOGLE_API_KEY"] = ""


from langchain.utilities import GoogleSearchAPIWrapper

search = GoogleSearchAPIWrapper()
search.run("Obama's first name?")
Â 
Â 
ì—¬ê¸°ê¹Œì§€ LangChain ì— ëŒ€í•´ì„œ ê°€ë³ê²Œ? ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤.
ì—¬ê¸°ì—ëŠ” ë¯¸ì²˜ ì •ë¦¬í•˜ì§€ ëª»í–ˆì§€ë§Œ ìœ ìš©í•œ ê²ƒë“¤ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì €ë„ LangChain ì„ ê³„ì† ì¨ë³´ë©´ì„œ ê¸°ì—¬í•  ë¶€ë¶„ì´ ìˆëŠ”ì§€ ì‚´í´ë³´ê³ ì í•©ë‹ˆë‹¤.
ê·¸ë¦¬ê³  ë§Œì•½ ìœ ìš©í•˜ê²Œ ì‚¬ìš©ì¤‘ì¸ ì»´í¬ë„ŒíŠ¸ê°€ ìˆë‹¤ë©´ ì‚¬ìš© ì˜ˆì œì™€ í•¨ê»˜ ê³µìœ í•´ì£¼ì‹œëŠ” ê²ƒë„ ì¢‹ê² ë„¤ìš”. ^^
Â 
Â 
ì°¸ê³ ë¬¸ì„œ

Â 

ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain
LangChain is a framework for developing applications powered by language models.
docs.langchain.com


Â 

Â 

GitHub - gkamradt/langchain-tutorials: Overview and tutorial of the LangChain Library
Overview and tutorial of the LangChain Library. Contribute to gkamradt/langchain-tutorials development by creating an account on GitHub.
github.com


Â 
ì¶œì²˜: https://revf.tistory.com/280 [RevFactory í”„ë¡œì íŠ¸ - ì„¸ìƒì„ ë” ì´ë¡­ê²Œ ë°”ê¾¸ëŠ” ì‘ì—…:í‹°ìŠ¤í† ë¦¬]